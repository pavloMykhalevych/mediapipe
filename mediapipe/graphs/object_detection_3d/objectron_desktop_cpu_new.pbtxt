# MediaPipe Objectron 3D object detection on Desktop CPU.
input_side_packet: "INPUT_FILE_PATH:input_video_path"
input_side_packet: "FILE_PATH:0:box_landmark_model_path"
input_side_packet: "LABELS_CSV:allowed_labels"
input_side_packet: "OUTPUT_FILE_PATH:output_video_path"

node {
  calculator: "ConstantSidePacketCalculator"
  output_side_packet: "PACKET:0:max_num_objects"
  output_side_packet: "PACKET:1:use_prev_landmarks"
  output_side_packet: "PACKET:2:min_tracking_threshold"
  output_side_packet: "PACKET:3:min_detecting_threshold"
  output_side_packet: "PACKET:4:input_focal_x"
  output_side_packet: "PACKET:5:input_focal_y"
  output_side_packet: "PACKET:6:input_principal_point_x"
  output_side_packet: "PACKET:7:input_principal_point_y"
  node_options: {
    [type.googleapis.com/mediapipe.ConstantSidePacketCalculatorOptions]: {
      packet { int_value: 5 }
      packet { bool_value: true }
      packet { double_value: 0.5 }
      packet { double_value: 0.5 }
      packet { double_value: 3.289440038111545 }
      packet { double_value: 1.8534927799704017 }
      packet { double_value: 0.002126283487971471 }
      packet { double_value: 0.03415198972509792 }
    }
  }
}

# Decodes an input video file into images and a video header.
node {
  calculator: "OpenCvVideoDecoderCalculator"
  input_side_packet: "INPUT_FILE_PATH:input_video_path"
  output_stream: "VIDEO:input_video"
  output_stream: "VIDEO_PRESTREAM:input_video_header"
}

# Run Objectron subgraph.
node {
  calculator: "ObjectronCpuWithCalibrationSubgraph"
  input_stream: "IMAGE:input_video"
  input_side_packet: "MODEL_PATH:box_landmark_model_path"
  input_side_packet: "LABELS_CSV:allowed_labels"
  input_side_packet: "MAX_NUM_OBJECTS:max_num_objects"
  input_side_packet: "USE_PREV_LANDMARKS:use_prev_landmarks"
  input_side_packet: "MIN_TRACKING_THRESHOLD:min_tracking_threshold"
  input_side_packet: "MIN_DETECTING_THRESHOLD:min_detecting_threshold"
  input_side_packet: "INPUT_FOCAL_X:input_focal_x"
  input_side_packet: "INPUT_FOCAL_Y:input_focal_y"
  input_side_packet: "INPUT_PRINCIPAL_POINT_X:input_principal_point_x"
  input_side_packet: "INPUT_PRINCIPAL_POINT_Y:input_principal_point_y"
  output_stream: "FRAME_ANNOTATION:detected_objects"
  output_stream: "MULTI_LANDMARKS:multi_box_landmarks"
  output_stream: "NORM_RECTS:multi_box_rects"
}

# Subgraph that renders annotations and overlays them on top of the input
# images (see renderer_cpu.pbtxt).
node {
  calculator: "RendererSubgraph"
  input_stream: "IMAGE:input_video"
  input_stream: "MULTI_LANDMARKS:multi_box_landmarks"
  input_stream: "NORM_RECTS:multi_box_rects"
  output_stream: "IMAGE:output_video"
}

# Encodes the annotated images into a video file, adopting properties specified
# in the input video header, e.g., video framerate.
node {
  calculator: "OpenCvVideoEncoderCalculator"
  input_stream: "VIDEO:output_video"
  input_stream: "VIDEO_PRESTREAM:input_video_header"
  input_side_packet: "OUTPUT_FILE_PATH:output_video_path"
  node_options: {
    [type.googleapis.com/mediapipe.OpenCvVideoEncoderCalculatorOptions]: {
      codec: "avc1"
      video_format: "mp4"
    }
  }
}
